events {
  ## Must be present even if it's empty
}

http {
  upstream backend {
    server caching-content:4500;
  }

  ## Cache for static files
  ## Keyzone size 100MB of memory, cache size 5GB of disk, inactive delete 30min
  proxy_cache_path /var/cache/static levels=1:2 keys_zone=static:60m max_size=5g inactive=30m use_temp_path=off;

  ## Cache for dynamic content by ip
  ## Keyzone size 8MB of memory, cache size 50MB of disk, inactive delete 10min
  proxy_cache_path /var/cache/dynamic levels=1:2 keys_zone=dynamic:8m max_size=50m inactive=10m use_temp_path=off;

  ## Generic cache key
  proxy_cache_key  $scheme$request_method$host$request_uri;

  ## Avoid showing nginx version
  server_tokens off;

  server {
    listen 8080;

    ## Redirections must be explicit on location
    proxy_redirect        off;

    ## Headers for the backend
    proxy_set_header      Host $host;
    proxy_set_header      X-Real-IP $remote_addr;
    proxy_set_header      X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header      X-Forwarded-Host $server_name;

    ## General cache settings
    proxy_cache_methods   GET HEAD;
    proxy_cache_valid     200 30m;

    ## Headers for the client
    expires               30m;
    add_header            Cache-Control "public";
    add_header            X-Cache-Status $upstream_cache_status;

    location / {
      ## Server url (The one set in the upstream section)
      proxy_pass          http://backend;
      ## Set the cache key for static locations
      proxy_cache           static;
    }

    location /v1/ping {
      ## Server url (The one set in the upstream section)
      proxy_pass          http://backend;
      ## Turn off the cache for ping service
      proxy_cache         off;
    }

    location /v1/file {
        ## Server url (The one set in the upstream section)
        proxy_pass            http://backend;
        ## Set the cache key for static locations
        proxy_cache           static;
        ## Force request that are competing for the same element to wait until the cache has been populated
        ## This way the backend only receives one request for the same element
        proxy_cache_lock      on;
        ## If the cache hadn't been populated after one second nginx let the requests continue their way to the backend
        proxy_cache_lock_timeout 1s;
    }

    location /v1/location {
        ## Server url (The one set in the upstream section)
        proxy_pass            http://backend;
        ## Set the dynamic cache for location settings for location
        proxy_cache_key       $scheme$request_method$host$request_uri$remote_addr;
        proxy_cache           dynamic;
        proxy_cache_valid     200 404 302 2d;
        expires               2d;
    }
  }
}
